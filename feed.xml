<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://yashjakhotiya.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://yashjakhotiya.github.io/blog/" rel="alternate" type="text/html" /><updated>2021-11-07T21:39:54-06:00</updated><id>https://yashjakhotiya.github.io/blog/feed.xml</id><title type="html">Blog</title><subtitle>Blog</subtitle><entry><title type="html">pinv¬†¬ª&amp;gt; inv</title><link href="https://yashjakhotiya.github.io/blog/linear%20algebra/2021/11/07/moore-penrose-inversion.html" rel="alternate" type="text/html" title="pinv &gt;&gt;&gt; inv" /><published>2021-11-07T00:00:00-05:00</published><updated>2021-11-07T00:00:00-05:00</updated><id>https://yashjakhotiya.github.io/blog/linear%20algebra/2021/11/07/moore-penrose-inversion</id><content type="html" xml:base="https://yashjakhotiya.github.io/blog/linear%20algebra/2021/11/07/moore-penrose-inversion.html">&lt;p&gt;In this post, let‚Äôs go all the way back to something as ‚Äúbasic‚Äù as linear regression and it‚Äôs closed form solution through least squares method and try to unearth a couple of linear algebra gems.&lt;/p&gt;

&lt;h1 id=&quot;when-explicit-formulation-failed&quot;&gt;When explicit formulation failed&lt;/h1&gt;
&lt;p&gt;In an ML class, we were told to find out weights to a linear regression problem through least squares method, before we went to gradient descent. My first instinct was to use the formulation (derivation in the &lt;a href=&quot;https://mahdi-roozbahani.github.io/CS46417641-fall2021/course/15-linear-regression-note.pdf&quot;&gt;slides&lt;/a&gt;) -&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;Œ∏&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;‚àí&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\theta = (X^TX)^{-1}X^TY&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.69444em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;Œ∏&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.1413309999999999em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8913309999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.864108em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;‚àí&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8913309999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.22222em;&quot;&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;But I didn‚Äôt pass our autograder tests.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Because -&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The above formulation has an assumption that $X^TX$ has to be invertible.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This will happen if rank of $X^TX$, a DxD matrix, is equal to D.&lt;/p&gt;

&lt;p&gt;$rank(X^TX)$ is always equal to  $rank(X)$. So we effectively need  $rank(X)$ to be D.  $X$ has rank  $D$ when $N &amp;gt;= D$ and  $X$ has linearly independent columns (i.e. linear independence in the  $D$ dimension).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;BUT&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The autograder tests don‚Äôt have such assumptions. For example, if $N &amp;lt; D$ then $rank(X^TX) &amp;lt;= N &amp;lt; D$ OR if $N &amp;gt;= D$ and the columns (i.e. $X$‚Äôs features) are not linearly independent, which makes  $rank(X)$ again less than D, in which case we were told to use &lt;code class=&quot;highlighter-rouge&quot;&gt;pinv&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;But why &lt;code class=&quot;highlighter-rouge&quot;&gt;pinv&lt;/code&gt;? What is so special about it?&lt;/em&gt; Read on to find out!&lt;/p&gt;

&lt;h1 id=&quot;minimum-norm-solution---with-derivatives&quot;&gt;Minimum norm solution - with derivatives&lt;/h1&gt;
&lt;p&gt;Our aim in a linear regression problem to form a minimum norm solution, i.e. a solution which will have our loss (square of the norm, square of the L2 distance between predicted and true values) minimum. One approach to do this is by taking a derivative of the norm and equating to zero, which we did in class (slides &lt;a href=&quot;https://mahdi-roozbahani.github.io/CS46417641-fall2021/course/15-linear-regression-note.pdf&quot;&gt;here&lt;/a&gt;!), and which leads to the formulation -&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;Œ∏&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;X^TX\theta = X^TY&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8913309999999999em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8913309999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;Œ∏&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8913309999999999em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8913309999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.22222em;&quot;&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;But the problem here is $X^TX$ can be invertible or can not be invertible, as stated above in the first section.&lt;/p&gt;

&lt;h1 id=&quot;better-minimum-norm-solution---with-svd&quot;&gt;(Better) minimum norm solution - with SVD&lt;/h1&gt;
&lt;p&gt;Another approach to find a minimum norm solution is by first finding singular value decomposition of  $X$&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;U&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Œ£&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;X = UŒ£V^T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8913309999999999em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10903em;&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Œ£&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.22222em;&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8913309999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;and defining $X^+$ to be&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Œ£&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;U&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;X^+=VŒ£^+U^T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.821331em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.821331em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8913309999999999em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.22222em;&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;Œ£&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.821331em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10903em;&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8913309999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;where $Œ£^+$ is obtained by taking the reciprocal of each non-zero element on the diagonal, leaving the zeros in place, and then transposing the matrix.&lt;/p&gt;

&lt;p&gt;and finding theta by&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;Œ∏&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Œ£&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;U&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\theta = X^+Y = VŒ£^+U^TY&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.69444em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;Œ∏&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.821331em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.821331em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.22222em;&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8913309999999999em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.22222em;&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;Œ£&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.821331em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10903em;&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8913309999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.22222em;&quot;&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;The proof on why this theta gives the minimum norm solution is given &lt;a href=&quot;http://web.cs.ucla.edu/~chohsieh/teaching/CS260_Winter2019/notes_linearregression.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;enter-moore-penrose&quot;&gt;Enter Moore-Penrose&lt;/h1&gt;
&lt;p&gt;The NumPy &lt;code class=&quot;highlighter-rouge&quot;&gt;pinv&lt;/code&gt; we were using to solve the assignment was NOT&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;‚àí&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;(X^TX)^{-1}X^T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.1413309999999999em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8913309999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.864108em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;‚àí&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8913309999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;but the SVD $X^+$ defined above, also known as the Moore-Penrose inversion or ‚Äòpseudoinverse‚Äô. Don‚Äôt believe me? Look for yourself &lt;a href=&quot;https://numpy.org/doc/stable/reference/generated/numpy.linalg.`pinv`.html&quot;&gt;here&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;This is why our autograder tests passed when using &lt;code class=&quot;highlighter-rouge&quot;&gt;pinv&lt;/code&gt;, because we were giving a minimum norm solution without relying on $X^TX$ invertibility.&lt;/p&gt;

&lt;h1 id=&quot;relation-between-the-two-approaches&quot;&gt;Relation between the two approaches&lt;/h1&gt;
&lt;p&gt;But how does this Moore-Penrose inversion, the SVD based X^+ definition, the NumPy &lt;code class=&quot;highlighter-rouge&quot;&gt;pinv&lt;/code&gt; relate to what we proved in class? Well, it reduces to&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;‚àí&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;(X^TX)^{-1}X^T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.1413309999999999em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8913309999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.864108em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;‚àí&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8913309999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;when $X^TX$ is invertible!&lt;/p&gt;

&lt;p&gt;Read more about Moore-Penrose inversion &lt;a href=&quot;https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse&quot;&gt;here&lt;/a&gt;. The article defines Moore-Penrose inversion based on 4 Moore-Penrose conditions and then arrives at SVD based computation, but both of these are equivalent. You can define by SVD based computation and then prove those 4 conditions. Also, don‚Äôt worry about the A* notation there. It is known as Hermitian transpose, and is equal to the ‚Äòvanilla‚Äô transpose for real numbers.&lt;/p&gt;

&lt;p&gt;Please feel free to correct me if you feel there‚Äôs a mistake anywhere.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;</content><author><name>&lt;a href='https://www.linkedin.com/in/yash-jakhotiya/'&gt;Yash Jakhotiya&lt;/a&gt;</name></author><summary type="html">In this post, let‚Äôs go all the way back to something as ‚Äúbasic‚Äù as linear regression and it‚Äôs closed form solution through least squares method and try to unearth a couple of linear algebra gems.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://yashjakhotiya.github.io/blog/images/moore-penrose.png" /><media:content medium="image" url="https://yashjakhotiya.github.io/blog/images/moore-penrose.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">On Continual Learning</title><link href="https://yashjakhotiya.github.io/blog/continual%20learning/lifelong%20learning/2021/10/23/continual-learning.html" rel="alternate" type="text/html" title="On Continual Learning" /><published>2021-10-23T00:00:00-05:00</published><updated>2021-10-23T00:00:00-05:00</updated><id>https://yashjakhotiya.github.io/blog/continual%20learning/lifelong%20learning/2021/10/23/continual-learning</id><content type="html" xml:base="https://yashjakhotiya.github.io/blog/continual%20learning/lifelong%20learning/2021/10/23/continual-learning.html">&lt;h1 id=&quot;why-care-the-problem-and-my-personal-encounter-with-it&quot;&gt;Why care? The problem and my personal encounter with it&lt;/h1&gt;
&lt;p&gt;In a past internship in a large company‚Äôs private cloud department, I was tasked to train a model that would predict which on-call engineer an infrastuctural alert should go to, with features that ranged from time of the day to the alert‚Äôs natural language description. Fair enough. There goes two months of feature engineering, adapting and evaluating state-of-the-art models, hyperparameter tuning, finalising a two-stage network and deployment, and we have a module that performs acceptably well. All stakeholders are happy. Pushed to prod!&lt;/p&gt;

&lt;p&gt;Does the story end there? Nope. You see, a large dynamic private cloud has new alerts added every week. Can we feed in the new alerts and expect our module to spit something out? Yes. Can we assume that our on-call engineer roles, our classes, will always be the same? Probably not. Can we assume these new alerts are from an identical distribution as the old ones? Definitely not. (You‚Äôd be surprised at the number of new and innovative problems that arise in a complex cloud environment!)&lt;/p&gt;

&lt;p&gt;How do you make sure in this case, that your network learns to correctly classify these new alerts? A naive strategy would be to retrain the model on the whole (old + new) alerts data. This might work if -
i. the network training time is bearable
ii. the addition of new data doesn‚Äôt quickly result in a storage problem, especially if new data is available as a regular stream
iii. you‚Äôll always have access to old data without any legal or privacy concerns.&lt;/p&gt;

&lt;p&gt;However, more of than you‚Äôd expect, one of the above assumptions gets violated and you are forced to think how to go about including newer data in your model. Another naive strategy would be to fine-tune the old model on newer data, and expect it to perform well on everything. In this case, you are in for another suprise - of how quickly your model learns to forget older data. Eventually, this leads us to ‚Ä¶&lt;/p&gt;

&lt;h1 id=&quot;the-problem-of-catastrophic-forgetting&quot;&gt;The problem of catastrophic forgetting&lt;/h1&gt;
&lt;p&gt;As early as in 1989, McCloskey and Cohen&lt;a href=&quot;McCloskey, M. and Cohen, N. J. (1989). Catastrophic interference in connectionist networks: The&quot;&gt;3&lt;/a&gt; identified a problem - when trained sequentially on new data, classes and tasks, a neural network‚Äôs performance degrades at previously learned concepts. They named this ‚Äòcatastrophic interference‚Äô, now commonly known as catastrophic forgetting. This usually happens when a new task overrides previously learned weights, interfering with performance on past tasks. Abraham and Robins&lt;a href=&quot;Abraham WC, Robins A. Memory retention--the synaptic stability versus plasticity dilemma. Trends Neurosci. 2005;28(2):73-78. doi:10.1016/j.tins.2004.12.003&quot;&gt;4&lt;/a&gt; referred to this as the ‚Äòstability-plasticity dilemma‚Äô, where a model too &lt;em&gt;stable&lt;/em&gt; won‚Äôt be able to learn new tasks and a model too &lt;em&gt;plastic&lt;/em&gt; will have it‚Äôs weights too changed to forget older ones. The research that goes into addressing catastrophic forgetting&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;
&lt;p&gt;author    = {Timoth{'{e}}e Lesort},
  title     = {Continual Learning: Tackling Catastrophic Forgetting in Deep Neural
               Networks with Replay Processes},
  journal   = {CoRR},
  volume    = {abs/2007.00487},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.00487},
  eprinttype = {arXiv},
  eprint    = {2007.00487},
  timestamp = {Mon, 06 Jul 2020 15:26:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-00487.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}&lt;/p&gt;

&lt;p&gt;author = {Chen, Zhiyuan and Liu, Bing and Brachman, Ronald and Stone, Peter and Rossi, Francesca},
title = {Lifelong Machine Learning},
year = {2018},
isbn = {1681733021},
publisher = {Morgan &amp;amp; Claypool Publishers},
edition = {2nd},
abstract = {Lifelong Machine Learning, Second Edition is an introduction to an advanced machine
learning paradigm that continuously learns by accumulating past knowledge that it
then uses in future learning and problem solving. In contrast, the current dominant
machine learning paradigm learns in isolation: given a training dataset, it runs a
machine learning algorithm on the dataset to produce a model that is then used in
its intended application. It makes no attempt to retain the learned knowledge and
use it in subsequent learning. Unlike this isolated system, humans learn effectively
with only a few examples precisely because our learning is very knowledge-driven:
the knowledge learned in the past helps us learn new things with little data or effort.
Lifelong learning aims to emulate this capability, because without it, an AI system
cannot be considered truly intelligent. Research in lifelong learning has developed
significantly in the relatively short time since the first edition of this book was
published. The purpose of this second edition is to expand the definition of lifelong
learning, update the content of several chapters, and add a new chapter about continual
learning in deep neural networkswhich has been actively researched over the past two
or three years. A few chapters have also been reorganized to make each of them more
coherent for the reader. Moreover, the authors want to propose a unified framework
for the research area. Currently, there are several research topics in machine learning
that are closely related to lifelong learningmost notably, multi-task learning, transfer
learning, and meta-learningbecause they also employ the idea of knowledge sharing
and transfer. This book brings all these topics under one roof and discusses their
similarities and differences. Its goal is to introduce this emerging machine learning
paradigm and present a comprehensive survey and review of the important research results
and latest ideas in the area. This book is thus suitable for students, researchers,
and practitioners who are interested in machine learning, data mining, natural language
processing, or pattern recognition. Lecturers can readily use the book for courses
in any of these related fields.}
}&lt;/p&gt;

&lt;p&gt;sequential learning problem. In Psychology of learning and motivation, volume 24, pages 109‚Äì165.
Elsevier.&lt;/p&gt;</content><author><name>&lt;a href='https://www.linkedin.com/in/yash-jakhotiya/'&gt;Yash Jakhotiya&lt;/a&gt;</name></author><summary type="html">Why care? The problem and my personal encounter with it In a past internship in a large company‚Äôs private cloud department, I was tasked to train a model that would predict which on-call engineer an infrastuctural alert should go to, with features that ranged from time of the day to the alert‚Äôs natural language description. Fair enough. There goes two months of feature engineering, adapting and evaluating state-of-the-art models, hyperparameter tuning, finalising a two-stage network and deployment, and we have a module that performs acceptably well. All stakeholders are happy. Pushed to prod!</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://yashjakhotiya.github.io/blog/images/2020-12-20-container-runtimes/runc_in_docker.png" /><media:content medium="image" url="https://yashjakhotiya.github.io/blog/images/2020-12-20-container-runtimes/runc_in_docker.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Can you, like, REALLY explain me this?</title><link href="https://yashjakhotiya.github.io/blog/resources/2021/10/11/list-of-resources.html" rel="alternate" type="text/html" title="Can you, like, REALLY explain me this?" /><published>2021-10-11T00:00:00-05:00</published><updated>2021-10-11T00:00:00-05:00</updated><id>https://yashjakhotiya.github.io/blog/resources/2021/10/11/list-of-resources</id><content type="html" xml:base="https://yashjakhotiya.github.io/blog/resources/2021/10/11/list-of-resources.html">&lt;p&gt;There are times when you need to look back to something and reassure yourself that you &lt;em&gt;really&lt;/em&gt; &lt;em&gt;really&lt;/em&gt; understand it. This is a dynamic work-in-progress list of resources that has, potentially in a distant past, helped me do that.&lt;/p&gt;

&lt;h1 id=&quot;linear-algebra-&quot;&gt;Linear Algebra :&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=P2LTAUO1TdA&quot;&gt;Change of basis&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=PFDu9oVAE-g&quot;&gt;Eigenvectors and Eigenvalues&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://yashjakhotiya.github.io/blog/linear%20algebra/2021/11/07/moore-penrose-inversion.html&quot;&gt;Matrix Ranks, Invertibility, SVD, Pseudoinverse&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;statistical-ml&quot;&gt;Statistical ML&lt;/h1&gt;

&lt;h2 id=&quot;probability-mle-em&quot;&gt;Probability, MLE, EM&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://courses.engr.illinois.edu/cs440/sp2011/slides/lecture15.pdf&quot;&gt;Multiple random variables probability review&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mahdi-roozbahani.github.io/CS46417641-fall2021/course/09-gaussian-mixture-note.pdf&quot;&gt;Generative modeling, Latent variables, GMMs, MLE, EM&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;naive-bayes-logistic---sigmoid-softmax&quot;&gt;Naive Bayes, Logistic - Sigmoid, Softmax&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://cocoxu.github.io/CS7650_fall2021/slides/lec2-ml.pdf&quot;&gt;MLE, Naive Bayes, Logistic&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;www.youtube.com/watch?v=8CWyBNX6eDo&quot;&gt;Logistic, Softmax, Cross-entropy, Logistic connection to a single neuron via sigmoid&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;neural-network-foundational&quot;&gt;Neural Network Foundational&lt;/h1&gt;

&lt;h2 id=&quot;space-transformation&quot;&gt;Space Transformation&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/&quot;&gt;Neural Networks, Manifolds, and Topology&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;backpropagation&quot;&gt;Backpropagation&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Ilg3gGewQ5U&quot;&gt;What is backpropagation really doing?&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=tIeHLnjs5U8&quot;&gt;Backpropagation calculus&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=yLYHDSv-288&quot;&gt;Backprop with practical considerations&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>&lt;a href='https://www.linkedin.com/in/yash-jakhotiya/'&gt;Yash Jakhotiya&lt;/a&gt;</name></author><summary type="html">There are times when you need to look back to something and reassure yourself that you really really understand it. This is a dynamic work-in-progress list of resources that has, potentially in a distant past, helped me do that.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://yashjakhotiya.github.io/blog/images/list-of-resources/linked-tori.png" /><media:content medium="image" url="https://yashjakhotiya.github.io/blog/images/list-of-resources/linked-tori.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Can we avoid repeated questions by identifying similar intent?</title><link href="https://yashjakhotiya.github.io/blog/nlp/2021/10/03/quora-question-pairs.html" rel="alternate" type="text/html" title="Can we avoid repeated questions by identifying similar intent?" /><published>2021-10-03T00:00:00-05:00</published><updated>2021-10-03T00:00:00-05:00</updated><id>https://yashjakhotiya.github.io/blog/nlp/2021/10/03/quora-question-pairs</id><content type="html" xml:base="https://yashjakhotiya.github.io/blog/nlp/2021/10/03/quora-question-pairs.html">&lt;p&gt;&lt;em&gt;Course project for &lt;a href=&quot;https://mahdi-roozbahani.github.io/CS46417641-fall2021/&quot;&gt;CS 7641&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;introductionbackground-&quot;&gt;Introduction/Background :&lt;/h1&gt;

&lt;p&gt;With public discussion forums becoming highly popular in recent times, especially with classes and work moving to an online setup, websites like Edstem, Piazza, Stack Overflow and Quora have a constant influx of a large volume of questions. Multiple questions with the same intent leads to redundancy, and waste of time, space and resources.&lt;/p&gt;

&lt;h1 id=&quot;problem-definition-&quot;&gt;Problem Definition :&lt;/h1&gt;

&lt;p&gt;The aim is to identify and flag questions with a high similarity index, and retain only canonical questions in order to make the work of administrative staff such as TAs/Professors easier in terms of answering repeated questions or questions of the same intent.&lt;/p&gt;

&lt;h1 id=&quot;methods&quot;&gt;Methods:&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Dataset: The dataset that we will be using is the Quora Question Pairs dataset&lt;sup&gt;[1]&lt;/sup&gt;. It consists of 404,290 pairs of questions. Each datapoint consists of a pairof questions and whether
or not they are similar.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Data preprocessing:
    &lt;ul&gt;
      &lt;li&gt;One augmentation method we plan to leverage is the transitive property of similarity and create more question pairs. Assuming a question is represented as ùëÑ&lt;sub&gt;ùëñ&lt;/sub&gt;. If ùëÑ&lt;sub&gt;1&lt;/sub&gt; - ùëÑ&lt;sub&gt;2&lt;/sub&gt; are similar and ùëÑ&lt;sub&gt;2&lt;/sub&gt; - ùëÑ&lt;sub&gt;3&lt;/sub&gt; are similar, then ùëÑ&lt;sub&gt;1&lt;/sub&gt; - ùëÑ&lt;sub&gt;3&lt;/sub&gt; will also be similar.&lt;/li&gt;
      &lt;li&gt;Other preprocessing techniques we intend to use are,
        &lt;ol&gt;
          &lt;li&gt;Noise Removal&lt;/li&gt;
          &lt;li&gt;Removing stopwords and punctuation&lt;/li&gt;
          &lt;li&gt;Tokenization&lt;/li&gt;
          &lt;li&gt;Lemmatization and stemming&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Training:
    &lt;ul&gt;
      &lt;li&gt;For each training iteration, we input questions in a pairwise fashion - ùëÑ&lt;sub&gt;ùëñ&lt;/sub&gt;, ùëÑ&lt;sub&gt;ùëó&lt;/sub&gt;.&lt;/li&gt;
      &lt;li&gt;The model learns representations of building blocks of both sentencesùëÑ&lt;sub&gt;ùëñ&lt;/sub&gt;‚àí&amp;gt;ŒΩ&lt;sub&gt;ùëñ&lt;/sub&gt;, ùëÑ&lt;sub&gt;ùëó&lt;/sub&gt;‚àí&amp;gt;ŒΩ&lt;sub&gt;ùëó&lt;/sub&gt;.&lt;/li&gt;
      &lt;li&gt;Next, these representations are concatenated ùë£&lt;sub&gt;ùëêùëúùëõ&lt;/sub&gt; = ùëêùëúùëõùëêùëéùë°(ŒΩ&lt;sub&gt;ùëñ&lt;/sub&gt;, ŒΩ&lt;sub&gt;ùëó&lt;/sub&gt;), and passed on to a feedforward neural network or a machine learning model ùêπ (ùë£ùëêùëúùëõ) that predicts whether two questions are similar or not.&lt;/li&gt;
      &lt;li&gt;‚àÄ questions ùëÑ&lt;sub&gt;ùëñ&lt;/sub&gt; Œµ question bank ùëÑ&lt;sub&gt;ùêµ&lt;/sub&gt;, we group them into clusters ùëê&lt;sub&gt;&lt;em&gt;1&lt;/em&gt;&lt;/sub&gt;,‚Ä¶,ùëê&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt; for efficient inference.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Inference:
    &lt;ul&gt;
      &lt;li&gt;For a query question ùëÑ&lt;sub&gt;ùëû&lt;/sub&gt; we identify the cluster ùëê&lt;sub&gt;ùëñ&lt;/sub&gt; it belongs to.&lt;/li&gt;
      &lt;li&gt;For all candidate questions ùëÑ&lt;sub&gt;ùëë&lt;/sub&gt; belonging to cluster ùëê&lt;sub&gt;ùëñ&lt;/sub&gt;, we find similarity ùë†ùëñùëö(ùëÑ&lt;sub&gt;ùëë&lt;/sub&gt;, ùëÑ&lt;sub&gt;ùëû&lt;/sub&gt;). With clustering we avoid finding similarities with all questions in the question bank, making inference efficient.&lt;/li&gt;
      &lt;li&gt;If for any ùëÑ&lt;sub&gt;ùëë&lt;/sub&gt; Œµ ùëê&lt;sub&gt;ùëñ&lt;/sub&gt;, if ùë†ùëñùëö(ùëÑ&lt;sub&gt;ùëë&lt;/sub&gt;, ùëÑ&lt;sub&gt;ùëû&lt;/sub&gt;) &amp;gt; ùë°‚Ñéùëüùëíùë†‚Ñéùëúùëôùëë, we flag that question as similar.&lt;/li&gt;
      &lt;li&gt;We also output ùë°ùëúùëù ‚àí ùëò similar questions based on ùë†ùëñùëö(ùëÑ&lt;sub&gt;ùëë&lt;/sub&gt;, ùëÑ&lt;sub&gt;ùëû&lt;/sub&gt;).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Models in consideration:
    &lt;ul&gt;
      &lt;li&gt;Potential models for learning representations
        &lt;ul&gt;
          &lt;li&gt;BERT-like models (RoBERTa, ALBERT, DeBERTa)&lt;/li&gt;
          &lt;li&gt;GPT models&lt;/li&gt;
          &lt;li&gt;XLNet&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Potential models for clustering
        &lt;ul&gt;
          &lt;li&gt;K-means&lt;/li&gt;
          &lt;li&gt;DBSCAN&lt;/li&gt;
          &lt;li&gt;GMM&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Potential models for finding similarity
        &lt;ul&gt;
          &lt;li&gt;Feedforward neural network&lt;/li&gt;
          &lt;li&gt;Gradient boosted trees&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://yashjakhotiya.github.io/blog//images/2021-10-03-quora-question-pairs/similar-questions-flow-chart.png&quot; alt=&quot;&quot; title=&quot;Model in action&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;potential-results-and-discussions&quot;&gt;Potential Results and Discussions:&lt;/h1&gt;
&lt;p&gt;We aim to confidently identify a representative question for a
query question input by a user, and further list the &lt;strong&gt;&lt;em&gt;top-k&lt;/em&gt;&lt;/strong&gt; most
relevant questions.&lt;/p&gt;

&lt;p&gt;We also hope to gain insight by clustering similar questions and
analyze the reason for their similarity, which may help in
downstream tasks such as automatic question tagging, and
personalized recommendation of questions basedon the field of
interest.&lt;/p&gt;

&lt;h1 id=&quot;proposed-timeline-and-responsibilities-&quot;&gt;Proposed Timeline and Responsibilities :&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://yashjakhotiya.github.io/blog/images/2021-10-03-quora-question-pairs/timeline.png&quot; alt=&quot;&quot; title=&quot;Timeline&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;references-&quot;&gt;References :&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs&lt;/li&gt;
  &lt;li&gt;D. A. Prabowo and G. Budi Herwanto, ‚ÄúDuplicate Question Detection in Question Answer Website using Convolutional Neural Network,‚Äù 2019 5th International Conference on Science and Technology (ICST), 2019, pp. 1-6, doi: 10.1109/ICST47872.2019.9166343.&lt;/li&gt;
  &lt;li&gt;Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina
Toutanova, ‚ÄúBERT: Pre-training of Deep Bidirectional
Transformers for Language Understanding‚Äù, arXiv:1810.&lt;/li&gt;
  &lt;li&gt;Tianqi Chen andCarlos Guestrin.2016.XGBoost: A Scalable Tree Boosting System. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD ‚Äò16). Association for Computing Machinery, New York,NY,USA,785‚Äì794.DOI:https://doi.org/10.1145/2939672.785.&lt;/li&gt;
  &lt;li&gt;Reynolds D.(2009)GaussianMixture Models. In:Li S.Z.,Jain A. (eds) Encyclopedia of Biometrics. Springer, Boston, MA. https://doi.org/10.1007/978-0-387-73003-5_&lt;/li&gt;
&lt;/ol&gt;</content><author><name>&lt;a href='https://www.linkedin.com/in/abhijithragav/'&gt;Abhijith Ragav&lt;/a&gt;, &lt;a href='https://www.linkedin.com/in/ajish-sekar/'&gt;Ajish Sekar&lt;/a&gt;, &lt;a href='https://www.linkedin.com/in/naveen-1999/'&gt;Naveen Narayanan&lt;/a&gt;, &lt;a href='https://www.linkedin.com/in/pranav-guruprasad-82697514a/'&gt;Pranav Guruprasad&lt;/a&gt;, &lt;a href='https://www.linkedin.com/in/yash-jakhotiya/'&gt;Yash Jakhotiya&lt;/a&gt;</name></author><summary type="html">Course project for CS 7641</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://yashjakhotiya.github.io/blog/images/2021-10-03-quora-question-pairs/similar-questions-flow-chart.png" /><media:content medium="image" url="https://yashjakhotiya.github.io/blog/images/2021-10-03-quora-question-pairs/similar-questions-flow-chart.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Containers, Container Runtimes, and What Kubernetes ‚ÄòDocker‚Äô Deprecation Really Means</title><link href="https://yashjakhotiya.github.io/blog/containers/kubernetes/2020/12/20/container-runtimes.html" rel="alternate" type="text/html" title="Containers, Container Runtimes, and What Kubernetes 'Docker' Deprecation Really Means" /><published>2020-12-20T00:00:00-06:00</published><updated>2020-12-20T00:00:00-06:00</updated><id>https://yashjakhotiya.github.io/blog/containers/kubernetes/2020/12/20/container-runtimes</id><content type="html" xml:base="https://yashjakhotiya.github.io/blog/containers/kubernetes/2020/12/20/container-runtimes.html">&lt;h1 id=&quot;containers-arent-they--like-some-sort-of-virtual-machines&quot;&gt;Containers? Aren‚Äôt they ‚Ä¶ like some sort of virtual machines?&lt;/h1&gt;

&lt;p&gt;Docker popularized the notion of using containers - &lt;em&gt;isolated environments leveraging OS-level virtualization&lt;/em&gt; where each running process sees the environment as one whole computer. This seems awfully similar to virtual machines, except that it isn‚Äôt. Containers differ from virtual machines in that each container does not host the entire operating system the way virtual machines do.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yashjakhotiya.github.io/blog/images/2020-12-20-container-runtimes/containers_vs_vms.png&quot; alt=&quot;&quot; title=&quot;Virtual Machines Vs Containers&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Container images&lt;/strong&gt;, which become running containers when instantiated, store the application code and any required dependencies mentioned in the image &lt;a href=&quot;https://docs.docker.com/engine/reference/builder/&quot;&gt;Dockerfile&lt;/a&gt;. When you don‚Äôt need to worry about dependencies, shipping applications from a developer‚Äôs laptop to production servers or public cloud environments becomes easier. You &lt;em&gt;could&lt;/em&gt; package your application as a custom built VM image relying on a fully functional traditional OS packaged with it, but container images are much more lightweight and can be easily maintained.&lt;/p&gt;

&lt;h1 id=&quot;but-every-dockerfile-i-see-ultimately-stems-from-an-os-image-doesnt-that-mean-container-images-have-their-own-os-installed&quot;&gt;But, every dockerfile I see ultimately stems from an OS image. Doesn‚Äôt that mean container images have their own OS installed?&lt;/h1&gt;

&lt;p&gt;This is an excellent question. Thanks for asking! To answer this, let us get some background context.&lt;/p&gt;

&lt;p&gt;In most modern OS, an application process runs in what is known as a &lt;strong&gt;user mode&lt;/strong&gt;. The idea here is to restrict the memory area accessible to an application process and prevent it from accessing and potentially corrupting memory areas associated with kernel and other application processes. This is implemented using &lt;a href=&quot;https://en.wikipedia.org/wiki/Virtual_memory&quot;&gt;Virtual memory&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Protection_ring&quot;&gt;Protection Rings&lt;/a&gt;, and assisted by hardware in the form of &lt;a href=&quot;en.wikipedia.org/wiki/Protected_mode&quot;&gt;Protected mode&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Memory_management_unit&quot;&gt;Memory Management Units&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Providing fault tolerance and computer security with this form of &lt;strong&gt;memory protection&lt;/strong&gt; effectively results in a typical OS being divided into two bifurcations - a user space and a kernel space. An application running in user space can access resources which it does not have direct access to (like I/O devices or files lying on a disk) with special requests to the kernel called &lt;a href=&quot;https://man7.org/linux/man-pages/man2/syscalls.2.html&quot;&gt;system calls&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yashjakhotiya.github.io/blog/images/2020-12-20-container-runtimes/user_space_kernel_space.png&quot; alt=&quot;&quot; title=&quot;A process in user space makes a system call&quot; /&gt;&lt;/p&gt;

&lt;p&gt;System calls serve as APIs for all &lt;strong&gt;userland&lt;/strong&gt; software to interact with the kernel. In the Linux world, all distros (a bit simplification here) run the same kernel. This makes it possible for the &lt;em&gt;userland software coming from Ubuntu to talk to a CentOS kernel&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;What you see inside a Dockerfile, which gets installed in the built image, is &lt;strong&gt;not a full-fledged OS&lt;/strong&gt;. It is the trimmed-down version of the userland software of the OS, &lt;em&gt;bare enough to talk to the host‚Äôs kernel&lt;/em&gt;. It is not uncommon to see containers with Ubuntu, CentOS, and Debian base run parallely on a RHEL7 host.&lt;/p&gt;

&lt;h1 id=&quot;ok-i-am-curious-how-is-this-implemented&quot;&gt;Ok. I am curious. How is this implemented?&lt;/h1&gt;

&lt;p&gt;To be honest, container implementation recipe is really not that difficult if you understand its three main ingredients - cgroups, namespaces and chroot. Let us focus on each of them below.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;cgroups&lt;/strong&gt;, or Control Groups is a Linux kernel feature. With cgroups you can &lt;em&gt;allocate, monitor, and limit resources&lt;/em&gt; - like CPU time, memory, or network bandwidth - to a process or a collection of processes. Linux command &lt;a href=&quot;https://linux.die.net/man/1/cgcreate&quot;&gt;cgcreate&lt;/a&gt; helps you create a control group, &lt;a href=&quot;https://linux.die.net/man/1/cgset&quot;&gt;cgset&lt;/a&gt; sets resource limits for the control group, and with &lt;a href=&quot;https://linux.die.net/man/1/cgexec&quot;&gt;cgexec&lt;/a&gt; you can run a command in the control group.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;A &lt;strong&gt;namespace&lt;/strong&gt; is another Linux kernel feature, with which you can &lt;em&gt;isolate a global resource&lt;/em&gt;. This creates an illusion of a separate instance of the resource to the processes running in the namespace, and any changes made are &lt;strong&gt;not visible outside&lt;/strong&gt;! The resources you can abstract this way include process IDs, hostnames, user IDs, etc. &lt;a href=&quot;https://man7.org/linux/man-pages/man1/unshare.1.html&quot;&gt;unshare&lt;/a&gt; [options] [&lt;em&gt;program&lt;/em&gt; [arguments]] is a Linux utility you can use to create namespaces (supplied in &lt;code class=&quot;highlighter-rouge&quot;&gt;options&lt;/code&gt;) and run &lt;code class=&quot;highlighter-rouge&quot;&gt;program&lt;/code&gt; in it. For example you can create a UTS (Unix Time Sharing) namespace, which controls host and domain names, using the -u option as illustrated below.
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; hostname                              # show current hostname 
personal-ubuntu
&amp;gt; unshare -u /bin/sh                    # run a shell instance with UTS namespace unshared from parent
&amp;gt; hostname a-different-hostname         # change hostname to a-different-hostname
&amp;gt; hostname                              # verify that the hostname has been changed
a-different-hostname
&amp;gt; exit                                  # exit from the shell process, effectively destroying the namespace
&amp;gt; hostname                              # voila!
personal-ubuntu                         # changing the hostname inside the namespace has no effect outside!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://linux.die.net/man/1/chroot&quot;&gt;chroot&lt;/a&gt; is a Linux utility that can &lt;em&gt;change the apparent root directory for a process and its children&lt;/em&gt;. Running &lt;code class=&quot;highlighter-rouge&quot;&gt;chroot NEWROOT command&lt;/code&gt; will run &lt;code class=&quot;highlighter-rouge&quot;&gt;command&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;NEWROOT&lt;/code&gt; as its apparent root directory. This modified environment is also called a &lt;strong&gt;chroot jail&lt;/strong&gt;, because &lt;code class=&quot;highlighter-rouge&quot;&gt;command&lt;/code&gt; can not name and hence can not normally access files outside &lt;code class=&quot;highlighter-rouge&quot;&gt;NEWROOT&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now that you have understood these three main concepts, let us create a container image from the following dockerfile, which we want to run.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM ubuntu:18.04
COPY script.py /app
CMD python /app/script.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This container image contains the ubuntu:18.04 userland file structure heirarchy, /app/script.py and some environment configuration. Ignoring the config part for now, &lt;strong&gt;your minimal implementation can run this image in just 4 steps&lt;/strong&gt;.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Export and extract contents of the image in &lt;code class=&quot;highlighter-rouge&quot;&gt;new_root_dir&lt;/code&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; mkdir new_root_dir
&amp;gt; docker export docker_image | tar -xf - -C new_root_dir
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Create a control group and set memory and CPU use limits
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; control_group=$(uuidgen)
&amp;gt; cgcreate -g cpu,memory:$control_group
&amp;gt; cgset -r memory.limit_in_bytes=50000000 $control_group
&amp;gt; cgset -r cpu.shares=256 $control_group
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Executing inside the control group, call unshare to separate namespaces and execute &lt;code class=&quot;highlighter-rouge&quot;&gt;script.py&lt;/code&gt; inside the &lt;code class=&quot;highlighter-rouge&quot;&gt;new_root_dir&lt;/code&gt; jail
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; cgexec -g cpu,memory:$control_group unshare -uinpUrf --mount-proc sh -c &quot;chroot new_root_dir /app/script.py&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Cleanup. Delete the cgroup and &lt;code class=&quot;highlighter-rouge&quot;&gt;new_root_dir&lt;/code&gt;. Unless bound to a file, namespaces cease to exist once all running processes in the namespace have exited.
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; cgdelete -r -g cpu,memory:$control_group
&amp;gt; rm -r new_root_dir
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Lo and behold!&lt;/strong&gt; You have just created a minimal container runtime!&lt;/p&gt;

&lt;h1 id=&quot;whoa-wait-container-r-what&quot;&gt;Whoa! Wait, Container R‚Ä¶ what?&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Container Runtime&lt;/strong&gt; - the code and tooling responsible for running containers. What you created above is the heart of what every container runtime does. Although, it catches the essence of container runtimes, it‚Äôs still minimal. Docker images also have something known as a &lt;code class=&quot;highlighter-rouge&quot;&gt;config.json&lt;/code&gt;. This file has, among other things, environment variables to be set for the running process inside the container, and the uid and gid of the user the process must run as.&lt;/p&gt;

&lt;p&gt;The code to run containers used to be deep inside a monolith called &lt;code class=&quot;highlighter-rouge&quot;&gt;Docker&lt;/code&gt;. But, it need not be. As long as vendors agree upon a common specification for images and a common specification for runtimes, &lt;em&gt;anybody could create runtimes&lt;/em&gt; customized to their needs. &lt;strong&gt;That‚Äôs exactly what they did&lt;/strong&gt;. Docker, CoreOS, Google and other industry leaders in the container space came together and launched &lt;a href=&quot;https://opencontainers.org&quot;&gt;Open Container Initiative&lt;/a&gt; in June 2015. OCI is responsible for defining &lt;a href=&quot;https://github.com/opencontainers/image-spec&quot;&gt;image-spec&lt;/a&gt; and &lt;a href=&quot;https://github.com/opencontainers/runtime-spec&quot;&gt;runtime-spec&lt;/a&gt;, which every OCI-compliant image builder and container runtime has to abide by.&lt;/p&gt;

&lt;p&gt;OCI even develops and maintains a reference implementation of the runtime-spec called &lt;a href=&quot;https://github.com/opencontainers/runc&quot;&gt;runc&lt;/a&gt;. runc broke off from Docker, as part of the Open Container Initiative. Although, runc is self-sufficient to run containers, it is a low-level runtime. The only developers that work with runc are developers of high-level runtimes.&lt;/p&gt;

&lt;h1 id=&quot;come-on-these-container-runtimes-have-levels-now&quot;&gt;Come on! These container runtimes have ‚Äòlevels‚Äô now?&lt;/h1&gt;

&lt;p&gt;Yes, they very much do! If you ever used Docker, you might know that running containers from images isn‚Äôt all that you do. You might want to &lt;strong&gt;pull images&lt;/strong&gt; from registries before you actually run them. A higher level runtime does that for you.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yashjakhotiya.github.io/blog/images/2020-12-20-container-runtimes/container_runtimes.png&quot; alt=&quot;&quot; title=&quot;A higher level runtime interacting with a lower level runtime&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Higher level runtimes are also responsible for &lt;strong&gt;unpacking&lt;/strong&gt; the container image into an &lt;a href=&quot;https://github.com/opencontainers/runtime-spec/blob/master/bundle.md&quot;&gt;OCI runtime bundle&lt;/a&gt; before spawning a runc process to run it. In addition to managing the lifecycle of a container, higher level runtimes are also sometimes responsible for low level storage and network namespace management. &lt;strong&gt;This is usually in place to facilitate interaction between individual container processes&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Humans aren‚Äôt the only entities that interact with higher level runtimes. &lt;a href=&quot;https://www.redhat.com/en/topics/containers/what-is-container-orchestration&quot;&gt;Container orchestration&lt;/a&gt; services (&lt;em&gt;just a fancy term for management and configuration of containers across large dynamic systems&lt;/em&gt;), like &lt;a href=&quot;https://kubernetes.io&quot;&gt;Kubernetes&lt;/a&gt;, need to interact with high-level runtimes. For most industry use-cases, it‚Äôs less humans and more such services that talk to these runtimes.&lt;/p&gt;

&lt;h1 id=&quot;did-you-mention-kubernetes-you-had-my-curiosity-now-you-have-my-attention&quot;&gt;Did you mention Kubernetes? You had my curiosity. Now you have my attention.&lt;/h1&gt;

&lt;p&gt;What interacts with high-level container runtimes are not client-facing modules of a running Kubernetes instance, &lt;strong&gt;but a node-agent called&lt;/strong&gt; &lt;a href=&quot;https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/&quot;&gt;kubelet&lt;/a&gt; which runs on all nodes in a Kubernetes cluster. &lt;strong&gt;Kubelet&lt;/strong&gt; is responsible to ensure all containers mentioned in a pod‚Äôs specification are running and healthy. It registers nodes, sends pod status and events, and reports resource utilization higher up the command chain.&lt;/p&gt;

&lt;p&gt;With the introduction of OCI, many container runtimes came up that supported running OCI-compliant container images, and &lt;strong&gt;so arised the need for Kubernetes to support multiple runtimes&lt;/strong&gt;. To avoid deep integration of such runtimes into kubelet source code, and the subsequent maintenance that would follow, Kubernetes introduced the &lt;a href=&quot;https://github.com/kubernetes/cri-api&quot;&gt;Container Runtime Interface&lt;/a&gt; - &lt;em&gt;an interface definition which enables kubelet to use a wide variety of runtimes&lt;/em&gt;. It is the responsibility of a container runtime to implement this interface as an internal package or as a &lt;strong&gt;shim&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/containerd&quot;&gt;containerd&lt;/a&gt;, a prominent high-level container runtime, which broke off from Docker similar to runc, recently merged its separate &lt;a href=&quot;https://github.com/containerd/cri&quot;&gt;cri-plugin&lt;/a&gt; codebase to its main &lt;a href=&quot;https://github.com/containerd/containerd&quot;&gt;containerd/containerd&lt;/a&gt; repository, &lt;strong&gt;marking CRI-implementation to be an important part of the container runtime&lt;/strong&gt;. &lt;a href=&quot;cri-o.io&quot;&gt;cri-o&lt;/a&gt; is another implementation of CRI, &lt;em&gt;focused and optimized only for Kubernetes&lt;/em&gt;, and, unlike containerd, can not service docker daemons for container orchestration.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yashjakhotiya.github.io/blog/images/2020-12-20-container-runtimes/kubelet_to_kernel.png&quot; alt=&quot;&quot; title=&quot;Kubelet to Kernel&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now that we have established CRI, let us talk about what the recent &lt;strong&gt;Kubernetes Docker Deprecation&lt;/strong&gt; really means.&lt;/p&gt;

&lt;h1 id=&quot;finally&quot;&gt;Finally!&lt;/h1&gt;

&lt;p&gt;Kuberenetes recently announced that it would be &lt;a href=&quot;https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.20.md#deprecation&quot;&gt;deprecating Docker&lt;/a&gt;. It really isn‚Äôt as dramatic as it sounds. What Kuberenetes will not support is &lt;strong&gt;Docker as a runtime&lt;/strong&gt;, and nothing else changes. Images built with dockerfiles are OCI-compliant and hence can be very well used with Kubernetes. Both containerd and cri-o know how to pull them, and runc knows how to run them.&lt;/p&gt;

&lt;p&gt;Docker, being built for human interaction, isn‚Äôt really friendly for Kubernetes as just a runtime. To interact with it, Kubernetes has to develop a module called &lt;strong&gt;dockershim&lt;/strong&gt;, which implements CRI support for Docker. This makes Docker call-able by kubelet as a runtime. Kubernetes is no longer willing to maintain this, especially when containerd (which Docker internally uses) has a CRI plugin. If you are developer, you do not really need to worry about what runtimes kubelet can interact with. &lt;strong&gt;Docker built images are perfectly fine for Kubernetes to consume!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yashjakhotiya.github.io/blog/images/2020-12-20-container-runtimes/dockershim_containerd.png&quot; alt=&quot;&quot; title=&quot;Dockershim deprecation&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;end-notes&quot;&gt;End Notes&lt;/h1&gt;

&lt;p&gt;I hope you liked reading this blog post as much as I loved writing it. I‚Äôll soon update a &lt;em&gt;large&lt;/em&gt; list of references which can be used for further reading. In the meanwhile, please feel free to follow me on &lt;a href=&quot;https://twitter.com/yash_jakhotiya&quot;&gt;Twitter&lt;/a&gt; and subscribe to the Blog‚Äôs &lt;a href=&quot;https://yashjakhotiya.github.io/blog/feed.xml&quot;&gt;RSS Feed&lt;/a&gt; for further updates. For any &lt;strong&gt;feedback or suggestions for blog posts&lt;/strong&gt;, please drop an &lt;a href=&quot;mailto:mailsforyashj@gmail.com&quot;&gt;email&lt;/a&gt; or DM on Twitter. Thanks for reading!&lt;/p&gt;</content><author><name>&lt;a href='https://www.linkedin.com/in/yash-jakhotiya/'&gt;Yash Jakhotiya&lt;/a&gt;</name></author><summary type="html">Containers? Aren‚Äôt they ‚Ä¶ like some sort of virtual machines?</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://yashjakhotiya.github.io/blog/images/2020-12-20-container-runtimes/runc_in_docker.png" /><media:content medium="image" url="https://yashjakhotiya.github.io/blog/images/2020-12-20-container-runtimes/runc_in_docker.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">GSoC ‚Äò20: Kubeflow Customer User Journey Notebooks with Tensorflow 2.x Keras</title><link href="https://yashjakhotiya.github.io/blog/open-source/mlops/2020/08/23/gsoc-kubeflow.html" rel="alternate" type="text/html" title="GSoC '20: Kubeflow Customer User Journey Notebooks with Tensorflow 2.x Keras" /><published>2020-08-23T00:00:00-05:00</published><updated>2020-08-23T00:00:00-05:00</updated><id>https://yashjakhotiya.github.io/blog/open-source/mlops/2020/08/23/gsoc-kubeflow</id><content type="html" xml:base="https://yashjakhotiya.github.io/blog/open-source/mlops/2020/08/23/gsoc-kubeflow.html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Open source software development and &lt;a href=&quot;https://summerofcode.withgoogle.com/&quot;&gt;Google Summer of Code&lt;/a&gt;, both started long before the summer of 2020. When the world was starting to grapple with the realities of &lt;a href=&quot;https://www.entrepreneur.com/article/354872&quot;&gt;remote work&lt;/a&gt;, open source community was already thriving on it. Over the course of my college years, I have found out three things that I am passionate about - open source, machine learning and &lt;a href=&quot;https://landing.google.com/sre/&quot;&gt;SRE&lt;/a&gt;. &lt;a href=&quot;https://www.kubeflow.org/&quot;&gt;Kubeflow&lt;/a&gt; has managed to incorporate all of these into one and doing a project with this organisation has been a dream come true!&lt;/p&gt;

&lt;h1 id=&quot;goal&quot;&gt;Goal&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt; is already an industry-standard in managing cloud resources. &lt;a href=&quot;https://www.kubeflow.org/&quot;&gt;Kubeflow&lt;/a&gt; is on its path to become an industry standard in managing machine learning workflows on cloud. Examples that illustrate Kubeflow functionalities using latest industry technologies make Kubeflow easier to use and more accessible to all potential users. This project has aimed at building samples for Jupyter notebook to Kubeflow deployment using Tensorflow 2.0 Keras for backend training code, illustrating customer user journey (CUJ) in the process. This project has also served as an hands-on to large scale application of machine learning bringing in the elements of DevOps and SRE and this has kept me motivated throughout the project.&lt;/p&gt;

&lt;h1 id=&quot;the-kubeflow-community&quot;&gt;The Kubeflow Community&lt;/h1&gt;

&lt;p&gt;The &lt;a href=&quot;https://www.kubeflow.org/docs/about/community/&quot;&gt;Kubeflow community&lt;/a&gt; is a highly approachable and closely-knit community that has been reaching out to and &lt;a href=&quot;https://www.kubeflow.org/docs/about/gsoc/&quot;&gt;helping&lt;/a&gt; potential GSoC students well before the application period. Respecting this, I made sure to take feedback for my proposal of the &lt;a href=&quot;https://summerofcode.withgoogle.com/projects/#5507335985823744&quot;&gt;project idea&lt;/a&gt; I chose, before the application deadline. Mentors &lt;a href=&quot;https://github.com/terrytangyuan&quot;&gt;Yuan Tang&lt;/a&gt;, &lt;a href=&quot;https://github.com/gaocegege&quot;&gt;Ce Gao&lt;/a&gt; and &lt;a href=&quot;https://github.com/ChanYiLin&quot;&gt;Jack Lin&lt;/a&gt; were candid in providing me feedback and I refined and changed my proposal accordingly. To my sweet surprise, I got selected for the idea!üòÅ What has really helped me in these three months of coding period is that one month of &lt;a href=&quot;https://developers.google.com/open-source/gsoc/timeline&quot;&gt;community bonding&lt;/a&gt; where I got to know the community and more about the technicalities of Kubeflow.&lt;/p&gt;

&lt;h1 id=&quot;the-project&quot;&gt;The Project&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://yashjakhotiya.github.io/blog/images/2020-08-23-gsoc-20-tf-2-examples/kubeflow_components.png&quot; alt=&quot;&quot; title=&quot;Kubeflow Components&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Examples created as part of this project needed to be easily reproducible to serve their purpose. Initially the underlying model decided to demonstrate Kubeflow functionalities was a BiDirectional RNN to be trained on IMDB large movie review &lt;a href=&quot;http://ai.stanford.edu/%7Eamaas/data/sentiment/&quot;&gt;dataset&lt;/a&gt; for sentiment analysis based on a &lt;a href=&quot;https://www.tensorflow.org/tutorials/text/text_classification_rnn&quot;&gt;tensorflow tutorial&lt;/a&gt;. Over the course of time, we decided to also add another set of examples using  a neural machine translation model in its backend trained on a Spanish to English &lt;a href=&quot;http://www.manythings.org/anki/&quot;&gt;dataset&lt;/a&gt; based on another &lt;a href=&quot;https://www.tensorflow.org/tutorials/text/nmt_with_attention&quot;&gt;tensorflow tutorial&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The reasons for choosing these models were:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;a href=&quot;https://github.com/kubeflow/examples&quot;&gt;kubeflow/examples&lt;/a&gt; repo needed more NLP-related tasks.&lt;/li&gt;
  &lt;li&gt;These were more of &lt;em&gt;hello world&lt;/em&gt; tasks in the field of NLP. So that users who go through these samples need not worry about training code and focus more on Kubeflow‚Äôs functionalities.&lt;/li&gt;
  &lt;li&gt;These are based on tensorflow tutorials. Kubeflow tutorials based on Tensorflow tutorials show better coupling between the two.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;repository-structure&quot;&gt;Repository Structure&lt;/h2&gt;

&lt;p&gt;I created a &lt;a href=&quot;https://github.com/yashjakhotiya/kubeflow-gsoc-2020&quot;&gt;repo&lt;/a&gt; under my own profile to regularly push commits to and my mentors consistently reviewed the work I pushed there. This repo has all of my work with the log history preserved. Each of the two models has the following folder structure explaining core Kubeflow functionalities -&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;training-model&amp;gt;.py&lt;/code&gt; - This is the core training code upon which all subsequent examples showing Kubeflow functionalities are based. Please go through this first to know more about the machine learning task subsequent notebooks will manage. For example check the &lt;a href=&quot;https://github.com/kubeflow/examples/blob/master/tensorflow_cuj/text_classification/text_classification_rnn.py&quot;&gt;source code&lt;/a&gt; of the model used for the text classification task.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;distributed_&amp;lt;training-model&amp;gt;.py&lt;/code&gt; - To truly take advantage of multiple compute nodes, the training code has to be modified to support distributed training. The code in the above mentioned file is modified with Tensorflow‚Äôs &lt;a href=&quot;https://www.tensorflow.org/guide/distributed_training&quot;&gt;distributed training&lt;/a&gt; strategy and hosted &lt;a href=&quot;https://github.com/kubeflow/examples/blob/master/tensorflow_cuj/text_classification/distributed_text_classification_rnn.py&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; - This is the dockerfile which is used to build Docker image of the training code. Some Kubeflow functionalities require that a docker image of the training code is built and hosted on a docker container registry. This Docker 101 &lt;a href=&quot;https://www.docker.com/101-tutorial&quot;&gt;tutorial&lt;/a&gt; is a good starting point to get hands-on training on Docker. For complete starters in the field of containerization, this &lt;a href=&quot;https://opensource.com/resources/what-docker&quot;&gt;introduction&lt;/a&gt; can serve as a good starting point. The dockerfile used with the source code mentioned above can be found &lt;a href=&quot;https://github.com/kubeflow/examples/blob/master/tensorflow_cuj/text_classification/Dockerfile&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fairing-with-python-sdk.ipynb&lt;/code&gt; - Fairing is a Kubeflow functionality that lets you run model training tasks remotely. This is the Jupyter notebook which deploys a model training task on cloud using Kubeflow Fairing. Fairing does not require you to build a Docker image of the training code first. Hence, its training code resides in the same notebook. To know more about Kubeflow Fairing, please visit Fairing‚Äôs &lt;a href=&quot;https://www.kubeflow.org/docs/components/fairing/fairing-overview/&quot;&gt;official documentation&lt;/a&gt;. To get a better idea about Fairing, you can take a look at the text classification Fairing notebook &lt;a href=&quot;https://github.com/kubeflow/examples/blob/master/tensorflow_cuj/text_classification/fairing-with-python-sdk.ipynb&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;katib-with-python-sdk.ipynb&lt;/code&gt; - &lt;a href=&quot;https://www.kubeflow.org/docs/components/hyperparameter-tuning/hyperparameter/&quot;&gt;Katib&lt;/a&gt; is a Kubeflow functionality that lets you perform hyperparameter tuning experiments and reports best set of hyperparameters based on a provided metric. This is the Jupyter notebook which launches Katib hyperparameter tuning experiments using its &lt;a href=&quot;https://github.com/kubeflow/katib/tree/master/sdk/python/v1alpha3&quot;&gt;Python SDK&lt;/a&gt;. Katib requires you to build and host a Docker image of your training code in a container registry. For this sample, we have used &lt;a href=&quot;https://cloud.google.com/cloud-build/docs&quot;&gt;gcloud builds&lt;/a&gt; to build the required Docker image of the training code along with the training data and host it on &lt;a href=&quot;https://cloud.google.com/container-registry&quot;&gt;Google Container Registry&lt;/a&gt;. This is the &lt;a href=&quot;https://github.com/kubeflow/examples/blob/master/tensorflow_cuj/text_classification/katib-with-python-sdk.ipynb&quot;&gt;notebook&lt;/a&gt; we used to demonstrate Katib for the text classification task.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tfjob-with-python-sdk.ipynb&lt;/code&gt; - &lt;a href=&quot;https://www.kubeflow.org/docs/components/training/tftraining/&quot;&gt;TFJobs&lt;/a&gt; are used to run distributed training jobs over Kubernetes. With multiple workers, TFJob truly leverage the ability of your code to support distributed training. This Jupyter notebook demonstrates how to use TFJob. The Docker image built from the distributed version of our core training code is used in this notebook. TFJob notebook for the text classification task can be found &lt;a href=&quot;https://github.com/kubeflow/examples/blob/master/tensorflow_cuj/text_classification/tfjob-with-python-sdk.ipynb&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tekton-pipeline-with-python-sdk.ipynb&lt;/code&gt; - &lt;a href=&quot;https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/&quot;&gt;Kubeflow Pipeline&lt;/a&gt; is a platform that lets you build, manage and deploy end-to-end machine learning workflows. This is a Jupyter notebook which bundles Katib hyperparameter tuning and TFJob distributed training into one Kubeflow pipeline. The pipeline used here uses &lt;a href=&quot;https://cloud.google.com/tekton&quot;&gt;Tekton&lt;/a&gt; in its backend. Tekton is a Kubernetes resource to create efficient &lt;a href=&quot;https://opensource.com/article/18/8/what-cicd&quot;&gt;continuous integration and delivery&lt;/a&gt; (CI/CD) systems. The pipeline notebook for the text classification task can be found at &lt;a href=&quot;https://github.com/kubeflow/examples/blob/master/tensorflow_cuj/text_classification/tekton-pipeline-with-python-sdk.ipynb&quot;&gt;this&lt;/a&gt; place.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;merged-prs&quot;&gt;Merged PRs&lt;/h2&gt;

&lt;p&gt;In the community bonding period, I opened numerous small issues and PRs solving these issues, as I encountered them when reading documentation or implementing an example. This was done in an effort to know more about the Kubeflow community.&lt;/p&gt;

&lt;p&gt;For the main project, I copied these built notebooks and the final work product into a directory created in my fork of the &lt;a href=&quot;https://github.com/kubeflow/examples&quot;&gt;kubeflow/examples&lt;/a&gt; repo and created a &lt;a href=&quot;https://github.com/kubeflow/examples/pull/816&quot;&gt;PR&lt;/a&gt; to add these notebooks in Kubeflow‚Äôs official repo. The PR got merged and the code currently resides in &lt;a href=&quot;https://github.com/kubeflow/examples/tree/master/tensorflow_cuj&quot;&gt;kubeflow/examples/tensorflow_cuj&lt;/a&gt; directory marking the completion of the project.&lt;/p&gt;

&lt;h1 id=&quot;special-thanks&quot;&gt;Special Thanks&lt;/h1&gt;

&lt;p&gt;Special thanks are due to -&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;My mentors for their valuable guidance throughout the project.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.linkedin.com/in/jeremy-lewi-600aaa8/&quot;&gt;Jeremy&lt;/a&gt; and &lt;a href=&quot;https://www.linkedin.com/in/sarahmaddox/&quot;&gt;Sarah&lt;/a&gt; for smooth conduction of the Kubeflow GSoC program.&lt;/li&gt;
  &lt;li&gt;The GSoC Discord &lt;a href=&quot;https://discord.com/channels/708636399666069514/708636400097951744&quot;&gt;Server&lt;/a&gt; and the GSoC Telegram &lt;a href=&quot;https://web.telegram.org/#/im?p=s1263176603_5411849872541551939&quot;&gt;Channel&lt;/a&gt; for the help, casual talks and a strong global student community.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>&lt;a href='https://www.linkedin.com/in/yash-jakhotiya/'&gt;Yash Jakhotiya&lt;/a&gt;</name></author><summary type="html">Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://yashjakhotiya.github.io/blog/images/2020-08-23-gsoc-20-tf-2-examples/logos.jpg" /><media:content medium="image" url="https://yashjakhotiya.github.io/blog/images/2020-08-23-gsoc-20-tf-2-examples/logos.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>